{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Barrier Labeling Method\n",
    "\n",
    "For more deatiles on this particular labeling method please refer to: De Prado, M. L. (2018). Advances in financial machine learning. John Wiley & Sons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_label(mid_prices, horizon, threshold, sequence_end):\n",
    "\n",
    "    # {0:STATIONARY 1:UP, 2:DOWN}\n",
    "    \n",
    "    # TRIPLE BARRIER METHOD\n",
    "    p_0 = mid_prices[sequence_end - 1]\n",
    "    upper_first_touched = None\n",
    "    lower_first_touched = None\n",
    "    window_mid_prices = mid_prices[sequence_end:sequence_end + horizon]\n",
    "\n",
    "    # Getting the returns\n",
    "    returns =  (window_mid_prices - p_0) / p_0\n",
    "\n",
    "    # Converting returns to numpy array\n",
    "    returns = np.array(returns)\n",
    "    upper_bar_index = np.where(returns > threshold)[0]\n",
    "    lower_bar_index = np.where(returns < -threshold)[0]\n",
    "\n",
    "    if upper_bar_index.size != 0:\n",
    "        upper_first_touched = upper_bar_index[0]\n",
    "\n",
    "    if lower_bar_index.size != 0:\n",
    "        lower_first_touched = lower_bar_index[0]\n",
    "\n",
    "    # Labeling\n",
    "    if upper_first_touched is not None:\n",
    "        label = 1 # UP\n",
    "\n",
    "        if lower_first_touched is not None:\n",
    "\n",
    "            if upper_first_touched < lower_first_touched:\n",
    "                pass # UP\n",
    "            else:\n",
    "\n",
    "                label = 2 # DOWN\n",
    "\n",
    "    elif lower_first_touched is not None:\n",
    "        label = 2 # DOWN\n",
    "\n",
    "    else:\n",
    "        label = 0 # STATIONARY\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the sequences \n",
    "\n",
    "The following code generates no overlapping sequences of length 100 time steps, the prediction horizon is set to 50, and the labeling method used is the one proposed by Marcos Lopez de Prado in his book \"Advances in Financial Machine Learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "mode = 'generate'\n",
    "labels_missing = False\n",
    "dataset_split = 'Training' # Options: ['Training', 'Validation', 'Test']\n",
    "data_type = 'stationary' \n",
    "seq_len = 100\n",
    "stride = 100\n",
    "horizon= 50\n",
    "threshol=0.000001\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "index = 0\n",
    "\n",
    "# We used the normalized files to have the same order in the dataset generation.\n",
    "normalized_files = [name for name in os.listdir(dataset_split + '/Normalized/') if os.path.splitext(name)[-2] != '.ipynb_checkpoints']\n",
    "\n",
    "for j, filename in enumerate(normalized_files):\n",
    "    if mode == 'generate':\n",
    "        # Loading the stationary data\n",
    "        with open(dataset_split + '/Normalized/' + filename, 'rb') as f:\n",
    "            data = torch.load(f)\n",
    "            \n",
    "    # Loading the mid prices\n",
    "    with open(dataset_split + '/Unscaled/' + filename.replace(ext, '.t'), 'rb') as f:\n",
    "        # Reading the data and loading tensor\n",
    "        unscaled = torch.load(f)\n",
    "        # We extract the mid-prices from the unscaled data\n",
    "        mid_prices = (unscaled[:, 0] + unscaled[:, 2]) / 2\n",
    "    \n",
    "    \n",
    "    start = 0\n",
    "    end = seq_len + start\n",
    "    \n",
    "    if dataset_split == 'Training': # We restart the sequences container as to avoid accumulating all tensors\n",
    "        sequences = []\n",
    "\n",
    "    while end <= len(mid_prices) - horizon:\n",
    "\n",
    "        sequence_labels = []\n",
    "        if mode == 'generate':\n",
    "            sequences.append(data[start:end].clone())\n",
    "        \n",
    "        if labels_missing:\n",
    "            # Getting the labels for the sentence\n",
    "            sequence_labels.append(set_label(mid_prices=mid_prices, \n",
    "                                             horizon, \n",
    "                                             threshold, \n",
    "                                             sequence_end=end))\n",
    "\n",
    "            labels.append(sequence_labels)\n",
    "\n",
    "        start = start + stride\n",
    "        end = seq_len + start\n",
    "    \n",
    "    \n",
    "    \n",
    "    if mode == 'generate':\n",
    "        # Stacking all sequences if applicable\n",
    "        if dataset_split == 'Training':\n",
    "            # Creating examples\n",
    "            number_of_sequences = len(sequences)\n",
    "            for count, value in enumerate(range(index, index + number_of_sequences)):\n",
    "                example=sequences[count]\n",
    "                with open(dataset_split + '/Dataset/' + f'{value}.t' , 'wb') as f:\n",
    "                    torch.save(example, f)\n",
    "\n",
    "            # Setting new temp len\n",
    "            index = index + number_of_sequences\n",
    "        \n",
    "    # Printing the number of filenames that are already processed\n",
    "    print('Filename_' + str(j))\n",
    "\n",
    "    \n",
    "if labels_missing:\n",
    "    # Converting labels to torch tensor\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Saving labels\n",
    "    with open(dataset_split + '/Labels/' + dataset_split.lower() + '_labels.t' , 'wb') as f:\n",
    "        torch.save(labels, f)\n",
    "\n",
    "if mode == 'generate':\n",
    "    if dataset_split == 'Training':\n",
    "        pass\n",
    "    else:\n",
    "        dataset = torch.stack(sequences) # shape [batch, sequence, features]\n",
    "\n",
    "        # Saving sequences\n",
    "        with open(dataset_split + '/Dataset/' + dataset_split.lower() + '_dataset.t' , 'wb') as f:\n",
    "            torch.save(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
